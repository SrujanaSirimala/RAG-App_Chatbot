**📚 RAG with Ebook using LangChain**  

This repository contains a Retrieval-Augmented Generation (RAG) implementation using LangChain and OpenAI models, based on Part 1 of LangChain's official RAG tutorial.  


Instead of the original blog post used in the tutorial, this project uses an ebook as the data source. The application allows users to ask questions about the ebook, with responses generated by a language model enhanced by document retrieval.  


**🚀 Features**  

Load and split an ebook into smaller chunks

Embed the chunks using OpenAI's embedding models

Store and search these embeddings using a vector store

Use LangChain's RAG pipeline to answer questions about the ebook

**📁 Project Structure**  

bash
Copy
Edit
.
├── .env                 # Stores API keys (not tracked in Git)
├── .gitignore           # Ensures .env and other sensitive files are ignored
├── ebook/               # Directory where the ebook is stored
├── embeddings/          # Vector store files (if persisted)
├── rag_with_ebook.ipynb # Main Jupyter Notebook implementing the pipeline
└── README.md            # Project documentation  

**🔑 Setup Instructions**  

Clone the repository:

bash
Copy
Edit
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
Create a .env file in the root directory and add your API keys:


**🧠 Technologies Used**  

LangChain

OpenAI GPT-4 / GPT-3.5 models

FAISS / Chroma (for vector storage)

Python

Jupyter Notebook

**✍️ Notes**  

Ensure the .env file is not pushed to GitHub. This project includes a .gitignore file to prevent that.

The notebook is written with modular and editable sections so you can easily swap in different documents or change model configurations.

**📖 Reference**  

LangChain RAG Tutorial (Part 1)

OpenAI API Documentation

